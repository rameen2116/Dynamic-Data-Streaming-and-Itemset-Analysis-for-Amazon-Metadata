Introduction:
This data pipeline orchestrates the process of mining association rules from a dataset of Amazon metadata. It begins with the sampling phase, where a subset of the dataset is selected based on a specified size. This step ensures that the subsequent processing is manageable and representative of the larger dataset. Following this, the preprocessing phase cleans and structures the sampled data, extracting essential information like titles, brands, and related products (both "also buy" and "also view" items), preparing it for further analysis. Once preprocessed, the data is fed into the producer, which publishes it to a Kafka topic, effectively making it available for consumption by various components.

Data Sampling and Preprocessing:
The pipeline then splits into multiple consumers, each responsible for a distinct aspect of association rule mining. The first consumer, aptly named Consumer1, ingests the preprocessed data from Kafka and applies the Apriori algorithm, a classic method for identifying frequent itemsets within transactional datasets. These frequent itemsets, comprising sets of items frequently purchased together, form the foundational elements for deriving association rules. Concurrently, Consumer2 receives the same stream of data, but it goes beyond identifying frequent itemsets; it also calculates association rules based on the discovered itemsets. It updates counts for individual items and pairs, computes frequent itemsets, and stores both frequent itemsets and association rules in MongoDB for subsequent analysis and application. Meanwhile, Consumer3 processes the data differently by constructing a conditional FP-tree, a specialized data structure for efficient mining of frequent itemsets. Leveraging this tree, Consumer3 mines additional frequent itemsets and stores them alongside their support values in MongoDB, contributing to a comprehensive collection of frequent itemsets for the dataset.

Conclusion:
Throughout the pipeline, data flows seamlessly from one stage to another, with each component fulfilling a crucial role in the overarching goal of association rule mining. By combining the power of Kafka for real-time data streaming, Python for data processing and analysis, and MongoDB for data storage, retrieval, and querying, this pipeline demonstrates a robust approach to extracting meaningful insights from large-scale datasets, ultimately empowering businesses with valuable knowledge about customer purchasing behavior and product associations.
